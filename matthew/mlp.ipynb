{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics.functional import binary_auprc\n",
    "\n",
    "from util_final import (\n",
    "    get_mlp,\n",
    "    normalize_features,\n",
    "    get_binary_cross_entropy,\n",
    "    get_binary_accuracy,\n",
    "    pbt,\n",
    "    AdamW\n",
    ")\n",
    "\n",
    "from sampling_methods import (\n",
    "    random_undersample,\n",
    "    smote,\n",
    "    knn_undersampling,\n",
    "    tomek_links\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "config = {\n",
    "        \"alpha\": 0.25,\n",
    "        \"dataset_path\": \"creditcard.pt\",\n",
    "        \"device\": device,\n",
    "        \"ensemble_shape\": (64,),\n",
    "        \"features_dtype\": torch.float32,\n",
    "        \"gamma\": 2.0,\n",
    "        \"labels_dtype\": torch.float32,\n",
    "        \"float_dtype\": torch.float32,\n",
    "        \"hyperparameter_raw_init_distributions\": {\n",
    "            \"epsilon\": torch.distributions.Uniform(\n",
    "                torch.tensor(-10, device=device, dtype=torch.float32),\n",
    "                torch.tensor(-5, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"first_moment_decay\": torch.distributions.Uniform(\n",
    "                torch.tensor(-3, device=device, dtype=torch.float32),\n",
    "                torch.tensor(0, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"learning_rate\": torch.distributions.Uniform(\n",
    "                torch.tensor(-5, device=device, dtype=torch.float32),\n",
    "                torch.tensor(-1, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"second_moment_decay\": torch.distributions.Uniform(\n",
    "                torch.tensor(-5, device=device, dtype=torch.float32),\n",
    "                torch.tensor(-1, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"weight_decay\": torch.distributions.Uniform(\n",
    "                torch.tensor(-5, device=device, dtype=torch.float32),\n",
    "                torch.tensor(-1, device=device, dtype=torch.float32)\n",
    "            )\n",
    "        },\n",
    "        \"hyperparameter_raw_perturb\": {\n",
    "            \"epsilon\": torch.distributions.Normal(\n",
    "                torch.tensor(0, device=device, dtype=torch.float32),\n",
    "                torch.tensor(1, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"first_moment_decay\": torch.distributions.Normal(\n",
    "                torch.tensor(0, device=device, dtype=torch.float32),\n",
    "                torch.tensor(1, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"learning_rate\": torch.distributions.Normal(\n",
    "                torch.tensor(0, device=device, dtype=torch.float32),\n",
    "                torch.tensor(1, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"second_moment_decay\": torch.distributions.Normal(\n",
    "                torch.tensor(0, device=device, dtype=torch.float32),\n",
    "                torch.tensor(1, device=device, dtype=torch.float32)\n",
    "            ),\n",
    "            \"weight_decay\": torch.distributions.Normal(\n",
    "                torch.tensor(0, device=device, dtype=torch.float32),\n",
    "                torch.tensor(1, device=device, dtype=torch.float32)\n",
    "            )\n",
    "        },\n",
    "        \"hyperparameter_transforms\": {\n",
    "            \"epsilon\": lambda log10: 10 ** log10,\n",
    "            \"first_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
    "            \"learning_rate\": lambda log10: 10 ** log10,\n",
    "            \"second_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
    "            \"weight_decay\": lambda log10: 10 ** log10\n",
    "        },\n",
    "        \"improvement_threshold\": 1e-4,\n",
    "        \"minibatch_size\": 128,\n",
    "        \"minibatch_size_eval\": 1 << 8,\n",
    "        \"pbt\": True,\n",
    "        \"seed\": 0,\n",
    "        \"steps_num\": 100_000,\n",
    "        \"steps_without_improvement\": 1000,\n",
    "        \"valid_interval\": 1000,\n",
    "        \"welch_confidence_level\": .95,\n",
    "        \"welch_sample_size\": 10,\n",
    "    }\n",
    "\n",
    "torch.manual_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, valid_features, valid_labels, test_features, test_labels = sampling_procedure(param) # TODO\n",
    "\n",
    "model = get_mlp(config, train_features.shape[-1], 1, 3, 128)\n",
    "optimizer = AdamW(model.parameters())\n",
    "\n",
    "output = pbt(\n",
    "    config,\n",
    "    get_binary_cross_entropy,\n",
    "    get_binary_accuracy,\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    valid_features,\n",
    "    valid_labels\n",
    ")\n",
    "\n",
    "pred_logits = model(test_features)\n",
    "accuracy = get_binary_accuracy(\n",
    "    config,\n",
    "    pred_logits,\n",
    "    test_labels\n",
    ")\n",
    "\n",
    "print(f'Accuracy: f{accuracy.max().item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
